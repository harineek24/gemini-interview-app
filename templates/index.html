<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Gemini Live Interview</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script>
        tailwind.config = {
            theme: {
                extend: {
                    animation: {
                        'pulse-custom': 'pulse 2s infinite',
                        'slide-in': 'slideIn 0.3s ease',
                    },
                    keyframes: {
                        slideIn: {
                            'from': { opacity: '0', transform: 'translateY(20px)' },
                            'to': { opacity: '1', transform: 'translateY(0)' }
                        }
                    }
                }
            }
        }
    </script>
</head>
<body class="bg-slate-100 min-h-screen p-5 font-sans">
    <div class="max-w-3xl mx-auto bg-white rounded-3xl p-8 shadow-2xl">
        <h1 class="text-center text-gray-800 mb-8 text-5xl font-light">üéôÔ∏è Gemini Live Interview</h1>
        
        <div class="status idle text-center mb-5 p-4 rounded-xl font-semibold bg-blue-50 text-blue-800" id="status">
            Ready to start interview
        </div>

        <div class="hidden bg-green-50 p-3 rounded-xl mb-5 text-center" id="interviewInfo">
            <strong>Interview ID:</strong> <span id="interviewId">-</span><br>
            <strong>Duration:</strong> <span id="duration">0:00</span>
        </div>

        <div class="flex justify-center gap-5 mb-8 flex-wrap">
            <button class="bg-green-500 hover:bg-green-600 text-white px-8 py-4 rounded-full text-base font-semibold cursor-pointer transition-all duration-300 uppercase tracking-wider hover:-translate-y-1 hover:shadow-lg" id="startBtn">
                Start Interview
            </button>
            <button class="bg-red-500 hover:bg-red-600 text-white px-8 py-4 rounded-full text-base font-semibold cursor-pointer transition-all duration-300 uppercase tracking-wider hover:-translate-y-1 hover:shadow-lg disabled:opacity-60 disabled:cursor-not-allowed disabled:hover:transform-none" id="stopBtn" disabled>
                Stop Interview
            </button>
        </div>

        <div class="bg-gray-50 rounded-2xl p-5 mb-5 max-h-96 overflow-y-auto border-2 border-gray-200">
            <div class="text-lg font-semibold text-gray-600 mb-4 text-center">Live Transcript</div>
            <div id="transcripts">
                <p class="text-center text-gray-500 italic">
                    Transcripts will appear here during the interview...
                </p>
            </div>
        </div>

        <div class="hidden bg-amber-50 rounded-2xl p-5 mt-5 border-2 border-amber-300" id="summaryContainer">
            <div class="text-lg font-semibold text-amber-700 mb-3">Interview Summary</div>
            <div id="summary" class="text-gray-700"></div>
        </div>
    </div>

    <script>
        class InterviewApp {
            constructor() {
                this.ws = null;
                this.audioContext = null;
                this.audioStream = null;
                this.audioProcessor = null;
                this.isRecording = false;
                this.interviewId = null;
                this.startTime = null;
                this.durationInterval = null;
                this.TARGET_SAMPLE_RATE = 16000;
                
                this.initializeElements();
                this.initializeEventListeners();
            }

            initializeElements() {
                this.startBtn = document.getElementById('startBtn');
                this.stopBtn = document.getElementById('stopBtn');
                this.status = document.getElementById('status');
                this.transcripts = document.getElementById('transcripts');
                this.summaryContainer = document.getElementById('summaryContainer');
                this.summary = document.getElementById('summary');
                this.interviewInfo = document.getElementById('interviewInfo');
                this.interviewIdSpan = document.getElementById('interviewId');
                this.durationSpan = document.getElementById('duration');
            }

            initializeEventListeners() {
                this.startBtn.addEventListener('click', () => this.startInterview());
                this.stopBtn.addEventListener('click', () => this.stopInterview());
            }

            async startInterview() {
                try {
                    // Connect to WebSocket
                    this.ws = new WebSocket('ws://localhost:8000/ws/interview');
                    
                    this.ws.onopen = () => {
                        console.log('WebSocket connected');
                        this.updateStatus('Connecting to Gemini Live...', 'active');
                    };

                    this.ws.onmessage = (event) => {
                        this.handleWebSocketMessage(JSON.parse(event.data));
                    };

                    this.ws.onclose = () => {
                        console.log('WebSocket closed');
                        this.resetInterface();
                    };

                    this.ws.onerror = (error) => {
                        console.error('WebSocket error:', error);
                        this.updateStatus('Connection failed', 'idle');
                        this.resetInterface();
                    };

                    // Request microphone access
                    await this.setupAudioRecording();
                    
                } catch (error) {
                    console.error('Error starting interview:', error);
                    this.updateStatus('Failed to start interview', 'idle');
                }
            }

            async setupAudioRecording() {
                try {
                    this.audioStream = await navigator.mediaDevices.getUserMedia({ 
                        audio: {
                            sampleRate: this.TARGET_SAMPLE_RATE,
                            channelCount: 1,
                            echoCancellation: true,
                            noiseSuppression: true
                        } 
                    });

                    this.audioContext = new (window.AudioContext || window.webkitAudioContext)({
                        sampleRate: this.TARGET_SAMPLE_RATE
                    });
                    
                    const source = this.audioContext.createMediaStreamSource(this.audioStream);
                    this.audioProcessor = this.audioContext.createScriptProcessor(4096, 1, 1);

                    this.audioProcessor.onaudioprocess = (event) => {
                        if (!this.isRecording) return;
                        
                        const inputData = event.inputBuffer.getChannelData(0);
                        const pcmData = this.floatTo16BitPCM(inputData);
                        const base64Audio = btoa(String.fromCharCode.apply(null, new Uint8Array(pcmData.buffer)));

                        if (this.ws && this.ws.readyState === WebSocket.OPEN) {
                            this.ws.send(JSON.stringify({
                                type: 'audio_chunk',
                                audio: base64Audio
                            }));
                        }
                    };

                    source.connect(this.audioProcessor);
                    this.audioProcessor.connect(this.audioContext.destination);

                    this.isRecording = true;

                } catch (error) {
                    console.error('Error setting up audio recording:', error);
                    // Attempt to fall back to default sample rate if specific one fails
                    if (error.name === 'NotSupportedError' || error.name === 'OverconstrainedError') {
                        console.log('Retrying audio with default sample rate...');
                        this.audioStream = await navigator.mediaDevices.getUserMedia({ audio: true });
                        // Re-run setup with the new stream
                        await this.setupAudioRecording();
                    } else {
                        throw error;
                    }
                }
            }
            
            floatTo16BitPCM(input) {
                const output = new Int16Array(input.length);
                for (let i = 0; i < input.length; i++) {
                    const s = Math.max(-1, Math.min(1, input[i]));
                    output[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
                }
                return output;
            }

            stopInterview() {
                if (this.ws && this.ws.readyState === WebSocket.OPEN) {
                    this.ws.send(JSON.stringify({ type: 'stop_interview' }));
                }
                this.cleanup();
            }

            cleanup() {
                this.isRecording = false;
                
                if (this.audioProcessor) {
                    this.audioProcessor.disconnect();
                    this.audioProcessor = null;
                }
                
                if (this.audioContext) {
                    this.audioContext.close();
                    this.audioContext = null;
                }

                if (this.audioStream) {
                    this.audioStream.getTracks().forEach(track => track.stop());
                    this.audioStream = null;
                }

                if (this.ws) {
                    this.ws.close();
                    this.ws = null;
                }

                if (this.durationInterval) {
                    clearInterval(this.durationInterval);
                    this.durationInterval = null;
                }
            }

            resetInterface() {
                this.startBtn.disabled = false;
                this.stopBtn.disabled = true;
                this.interviewInfo.classList.add('hidden');
                this.updateStatus('Ready to start interview', 'idle');
            }

            handleWebSocketMessage(data) {
                switch (data.type) {
                    case 'interview_started':
                        this.interviewId = data.interview_id;
                        this.interviewIdSpan.textContent = this.interviewId;
                        this.interviewInfo.classList.remove('hidden');
                        this.startTime = new Date();
                        this.startDurationTimer();
                        
                        this.startBtn.disabled = true;
                        this.stopBtn.disabled = false;
                        this.updateStatus('Interview in progress...', 'active');
                        
                        // Clear initial transcript message
                        this.transcripts.innerHTML = '';
                        break;

                    case 'live_transcript':
                        this.addTranscript(data.speaker, data.text);
                        break;

                    case 'audio_response':
                        this.playAudioResponse(data.audio, data.mime_type);
                        break;

                    case 'interview_ended':
                        this.updateStatus(`Interview completed (${data.duration})`, 'completed');
                        this.showSummary(data.summary);
                        this.cleanup();
                        this.resetInterface();
                        break;

                    default:
                        console.log('Unknown message type:', data.type);
                }
            }

            addTranscript(speaker, text) {
                const transcriptItem = document.createElement('div');
                transcriptItem.className = `mb-4 p-3 rounded-xl animate-slide-in ${
                    speaker === 'user' 
                        ? 'bg-blue-50 border-l-4 border-blue-500' 
                        : 'bg-purple-50 border-l-4 border-purple-500'
                }`;
                
                const speakerDiv = document.createElement('div');
                speakerDiv.className = `font-bold mb-1 uppercase text-xs tracking-wider ${
                    speaker === 'user' ? 'text-blue-700' : 'text-purple-700'
                }`;
                speakerDiv.textContent = speaker === 'user' ? 'You' : 'AI Interviewer';
                
                const textDiv = document.createElement('div');
                textDiv.className = 'text-gray-700';
                textDiv.textContent = text;
                
                transcriptItem.appendChild(speakerDiv);
                transcriptItem.appendChild(textDiv);
                
                this.transcripts.appendChild(transcriptItem);
                this.transcripts.scrollTop = this.transcripts.scrollHeight;
            }

            async playAudioResponse(base64Audio, mimeType) {
                try {
                    const audioData = atob(base64Audio);
                    const arrayBuffer = new ArrayBuffer(audioData.length);
                    const uint8Array = new Uint8Array(arrayBuffer);
                    
                    for (let i = 0; i < audioData.length; i++) {
                        uint8Array[i] = audioData.charCodeAt(i);
                    }

                    const audioContext = new (window.AudioContext || window.webkitAudioContext)();
                    const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
                    const source = audioContext.createBufferSource();
                    source.buffer = audioBuffer;
                    source.connect(audioContext.destination);
                    source.start();
                } catch (error) {
                    console.error('Error playing audio:', error);
                }
            }

            showSummary(summaryText) {
                this.summary.textContent = summaryText;
                this.summaryContainer.classList.remove('hidden');
            }

            updateStatus(text, className) {
                this.status.textContent = text;
                
                // Remove all status classes
                this.status.classList.remove('bg-blue-50', 'text-blue-800', 'bg-green-50', 'text-green-800', 'animate-pulse-custom', 'bg-amber-50', 'text-amber-700');
                
                // Add appropriate classes based on status
                switch(className) {
                    case 'idle':
                        this.status.classList.add('bg-blue-50', 'text-blue-800');
                        break;
                    case 'active':
                        this.status.classList.add('bg-green-50', 'text-green-800', 'animate-pulse-custom');
                        break;
                    case 'completed':
                        this.status.classList.add('bg-amber-50', 'text-amber-700');
                        break;
                }
            }

            startDurationTimer() {
                this.durationInterval = setInterval(() => {
                    const now = new Date();
                    const duration = Math.floor((now - this.startTime) / 1000);
                    const minutes = Math.floor(duration / 60);
                    const seconds = duration % 60;
                    this.durationSpan.textContent = `${minutes}:${seconds.toString().padStart(2, '0')}`;
                }, 1000);
            }
        }

        // Initialize the app when the page loads
        document.addEventListener('DOMContentLoaded', () => {
            new InterviewApp();
        });
    </script>
</body>
</html>